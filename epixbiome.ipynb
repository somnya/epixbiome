{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d622964-cf60-4e83-a31d-3e9d0ad560d5",
   "metadata": {},
   "source": [
    "# Quantitiative epi-genetics of the _A. thalinana_ root microbiome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab9e28e-e0c7-4a76-b845-f9a1c3760cdd",
   "metadata": {},
   "source": [
    "Author: Eddy J. Mendoza Galindo\n",
    "\n",
    "Masters Thesis at LMU from the MEME program\n",
    "\n",
    "Started in November 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ee75b0-472f-4a17-bf2d-6f363228a7ac",
   "metadata": {},
   "source": [
    "-----------IMPORTANT!!! \n",
    "\n",
    "To run properly all nextflow scripts, add this to the \".bashrc\" file in the home directory:\n",
    "ref=https://collab.dvb.bayern/display/LMUBEC/Storage+and+Cluster\n",
    "    \n",
    "\"#magic and poorly documented ENV variable that allows to omit the -M flag for (most) slurm commands\"\n",
    "\n",
    "export SLURM_CLUSTERS=biohpc_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c862d6c-9042-436a-b6e8-fc47cad65e19",
   "metadata": {},
   "source": [
    "--------IMPORTANT !!\n",
    "To use temporary directories (like Rscripts do) you need to set this enviromental variable:\n",
    "\n",
    "    export TMPDIR=path/\n",
    "    \n",
    "And make sure the path is compatible with your comands!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bd1192-54e4-4815-b0d2-8c1359345b48",
   "metadata": {},
   "source": [
    "#### Bisulfite DNA sequencing pipeline, public data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2f948bc1-328c-4771-9608-099e67bf3b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 ra42hux pn73so 513M Nov 17 12:46 taller/ra42hux/bs/SRR5631373_1.fastq.gz\n",
      "-rw-r--r-- 1 ra42hux pn73so 629M Nov 17 12:47 taller/ra42hux/bs/SRR5631373_2.fastq.gz\n",
      "-rw-r--r-- 1 ra42hux pn73so 527M Nov 17 12:47 taller/ra42hux/bs/SRR5631374_1.fastq.gz\n",
      "-rw-r--r-- 1 ra42hux pn73so 648M Nov 17 12:47 taller/ra42hux/bs/SRR5631374_2.fastq.gz\n",
      "-rw-r--r-- 1 ra42hux pn73so  32M Nov 17 14:02 taller/ra42hux/bs/SRR5631375_1.fastq.gz\n",
      "-rw-r--r-- 1 ra42hux pn73so  28M Nov 17 14:02 taller/ra42hux/bs/SRR5631375_2.fastq.gz\n",
      "-rw-r--r-- 1 ra42hux pn73so 932M Nov 17 12:41 taller/ra42hux/bs/SRR5631376_1.fastq.gz\n",
      "-rw-r--r-- 1 ra42hux pn73so 1.2G Nov 17 12:41 taller/ra42hux/bs/SRR5631376_2.fastq.gz\n",
      "-rw-r--r-- 1 ra42hux pn73so 478M Nov 17 12:42 taller/ra42hux/bs/SRR5631378_1.fastq.gz\n",
      "-rw-r--r-- 1 ra42hux pn73so 580M Nov 17 12:42 taller/ra42hux/bs/SRR5631378_2.fastq.gz\n",
      "-rw-r--r-- 1 ra42hux pn73so 466M Nov 17 12:43 taller/ra42hux/bs/SRR5631379_1.fastq.gz\n",
      "-rw-r--r-- 1 ra42hux pn73so 569M Nov 17 12:43 taller/ra42hux/bs/SRR5631379_2.fastq.gz\n",
      "-rw-r--r-- 1 ra42hux pn73so 508M Nov 17 12:44 taller/ra42hux/bs/SRR5631380_1.fastq.gz\n",
      "-rw-r--r-- 1 ra42hux pn73so 619M Nov 17 12:45 taller/ra42hux/bs/SRR5631380_2.fastq.gz\n",
      "-rw-r--r-- 1 ra42hux pn73so 498M Nov 17 12:43 taller/ra42hux/bs/SRR5631381_1.fastq.gz\n",
      "-rw-r--r-- 1 ra42hux pn73so 609M Nov 17 12:43 taller/ra42hux/bs/SRR5631381_2.fastq.gz\n",
      "-rw-r--r-- 1 ra42hux pn73so 502M Nov 17 12:44 taller/ra42hux/bs/SRR5631382_1.fastq.gz\n",
      "-rw-r--r-- 1 ra42hux pn73so 614M Nov 17 12:44 taller/ra42hux/bs/SRR5631382_2.fastq.gz\n",
      "-rw-r--r-- 1 ra42hux pn73so 491M Nov 17 12:45 taller/ra42hux/bs/SRR5631383_1.fastq.gz\n",
      "-rw-r--r-- 1 ra42hux pn73so 603M Nov 17 12:45 taller/ra42hux/bs/SRR5631383_2.fastq.gz\n",
      "-rw-r--r-- 1 ra42hux pn73so 477M Nov 17 12:45 taller/ra42hux/bs/SRR5631385_1.fastq.gz\n",
      "-rw-r--r-- 1 ra42hux pn73so 580M Nov 17 12:45 taller/ra42hux/bs/SRR5631385_2.fastq.gz\n",
      "-rw-r--r-- 1 ra42hux pn73so 467M Nov 17 12:46 taller/ra42hux/bs/SRR5631386_1.fastq.gz\n",
      "-rw-r--r-- 1 ra42hux pn73so 571M Nov 17 12:46 taller/ra42hux/bs/SRR5631386_2.fastq.gz\n",
      "-rw-r--r-- 1 ra42hux pn73so 533M Nov 17 12:47 taller/ra42hux/bs/SRR5631389_1.fastq.gz\n",
      "-rw-r--r-- 1 ra42hux pn73so 644M Nov 17 12:47 taller/ra42hux/bs/SRR5631389_2.fastq.gz\n",
      "-rw-r--r-- 1 ra42hux pn73so 526M Nov 17 12:48 taller/ra42hux/bs/SRR5631390_1.fastq.gz\n",
      "-rw-r--r-- 1 ra42hux pn73so 637M Nov 17 12:48 taller/ra42hux/bs/SRR5631390_2.fastq.gz\n",
      "-rw-r--r-- 1 ra42hux pn73so 536M Nov 17 12:48 taller/ra42hux/bs/SRR5631391_1.fastq.gz\n",
      "-rw-r--r-- 1 ra42hux pn73so 658M Nov 17 12:49 taller/ra42hux/bs/SRR5631391_2.fastq.gz\n",
      "-rw-r--r-- 1 ra42hux pn73so 525M Nov 17 12:49 taller/ra42hux/bs/SRR5631392_1.fastq.gz\n",
      "-rw-r--r-- 1 ra42hux pn73so 647M Nov 17 12:50 taller/ra42hux/bs/SRR5631392_2.fastq.gz\n"
     ]
    }
   ],
   "source": [
    "# First, I downloaded public paired-end data for 3 epiRILs and a Col0 WT (SRA PRJNA388579), in two replicates\n",
    "# eR92, eR150, eR193\n",
    "! ls -lh taller/ra42hux/bs/*.gz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc730672-f886-4152-adb6-6327191868c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID,line,rep\n",
      "SRR5631373,eR92,rep1\n",
      "SRR5631374,eR92,rep1\n",
      "SRR5631375,eR92,rep2\n",
      "SRR5631376,eR92,rep2\n",
      "SRR5631378,eR150,rep1\n",
      "SRR5631379,eR150,rep1\n",
      "SRR5631380,eR150,rep2\n",
      "SRR5631381,eR150,rep2\n",
      "SRR5631382,eR193,rep1\n",
      "SRR5631383,eR193,rep1\n",
      "SRR5631385,eR193,rep2\n",
      "SRR5631386,eR193,rep2\n",
      "SRR5631389,Col0,rep1\n",
      "SRR5631390,Col0,rep1\n",
      "SRR5631391,Col0,rep2\n",
      "SRR5631392,Col0,rep2\n"
     ]
    }
   ],
   "source": [
    "# metadata\n",
    "! cat taller/ra42hux/bs/SraAccList.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eacbaed1-39b5-4e47-9b79-801ed677f68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a samplesheet for methylseq\n",
    "! cat taller/ra42hux/bs/SraAccList.csv | tail -n +2 | sed -E 's/(\\w+),(\\w+),(\\w+)/\\2_\\3,bs\\/\\1_1.fastq.gz,bs\\/\\1_2.fastq.gz/g' > taller/ra42hux/bs/public_BS.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8158340a-9ef7-43f2-b337-0d679f8a1494",
   "metadata": {},
   "source": [
    "I added the headers manually as sugested in the documentation of methylseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4df61dfc-eb1a-47ea-8f2e-26970a8bb476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample,fastq_1,fastq_2\n",
      "eR92_rep1,bs/SRR5631373_1.fastq.gz,bs/SRR5631373_2.fastq.gz\n",
      "eR92_rep1,bs/SRR5631374_1.fastq.gz,bs/SRR5631374_2.fastq.gz\n",
      "eR92_rep2,bs/SRR5631375_1.fastq.gz,bs/SRR5631375_2.fastq.gz\n",
      "eR92_rep2,bs/SRR5631376_1.fastq.gz,bs/SRR5631376_2.fastq.gz\n",
      "eR150_rep1,bs/SRR5631378_1.fastq.gz,bs/SRR5631378_2.fastq.gz\n",
      "eR150_rep1,bs/SRR5631379_1.fastq.gz,bs/SRR5631379_2.fastq.gz\n",
      "eR150_rep2,bs/SRR5631380_1.fastq.gz,bs/SRR5631380_2.fastq.gz\n",
      "eR150_rep2,bs/SRR5631381_1.fastq.gz,bs/SRR5631381_2.fastq.gz\n",
      "eR193_rep1,bs/SRR5631382_1.fastq.gz,bs/SRR5631382_2.fastq.gz\n",
      "eR193_rep1,bs/SRR5631383_1.fastq.gz,bs/SRR5631383_2.fastq.gz\n",
      "eR193_rep2,bs/SRR5631385_1.fastq.gz,bs/SRR5631385_2.fastq.gz\n",
      "eR193_rep2,bs/SRR5631386_1.fastq.gz,bs/SRR5631386_2.fastq.gz\n",
      "Col0_rep1,bs/SRR5631389_1.fastq.gz,bs/SRR5631389_2.fastq.gz\n",
      "Col0_rep1,bs/SRR5631390_1.fastq.gz,bs/SRR5631390_2.fastq.gz\n",
      "Col0_rep2,bs/SRR5631391_1.fastq.gz,bs/SRR5631391_2.fastq.gz\n",
      "Col0_rep2,bs/SRR5631392_1.fastq.gz,bs/SRR5631392_2.fastq.gz"
     ]
    }
   ],
   "source": [
    "! cat taller/ra42hux/bs/public_BS.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f7730a-38fa-4ae7-aa13-a901e63a5ee2",
   "metadata": {},
   "source": [
    "## 20/11/23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f36e380-0f2a-4fbb-9d2b-17a7aaac834f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, I created an environment with nextflow and charliecloud versions that were compatible\n",
    "## The conda channels need to be in this order to use the conda profile:  [conda-forge, bioconda, defaults]\n",
    "conda create -n env_nf nextflow=21.10.0 charliecloud=0.27\n",
    "\n",
    "# to check both work:\n",
    "nextflow run hello\n",
    "ch-run -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f52668-bc6f-42df-b115-2856b99805a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I ran the nextflow pipeline, inside my scratch and the conda environment\n",
    "# using a Tmux console\n",
    "module load tmux/3.2a\n",
    "tmux\n",
    "\n",
    "nextflow \\\n",
    "\trun \\\n",
    "\tnf-core/methylseq \\\n",
    "\t--input 'bs/*{1,2}.fastq.gz' \\\n",
    "\t--genome TAIR10 \\\n",
    "\t--aligner bwameth \\\n",
    "\t--comprehensive \\\n",
    "\t--clip_r1 3 \\\n",
    "\t--clip_r2 3 \\\n",
    "\t--three_prime_clip_r1 3 \\\n",
    "\t--three_prime_clip_r2 3 \\\n",
    "\t--min_depth 3 \\\n",
    "\t--outdir methylseq/public_BS/ \\\n",
    "\t-profile biohpc_gen \\\n",
    "\t-r 1.6.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0577f73-c453-488a-abf6-3ff01d5d1bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "-[nf-core/methylseq] Pipeline completed successfully-\n",
    "Completed at: 20-Nov-2023 17:50:34\n",
    "Duration    : 4h 31m 38s\n",
    "CPU hours   : 73.3 (0.8% failed)\n",
    "Succeeded   : 129\n",
    "Ignored     : 4\n",
    "Failed      : 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e065a0f-917d-40c9-82db-727d4e9a2467",
   "metadata": {},
   "source": [
    "## 21/11/23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e64a760-f3bc-4f35-ad17-ea476c83ccc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taller/ra42hux/methylseq/public_BS/bwa-mem_markDuplicates/SRR5631373_1.sorted.markDups.bam\n",
      "taller/ra42hux/methylseq/public_BS/bwa-mem_markDuplicates/SRR5631374_1.sorted.markDups.bam\n",
      "taller/ra42hux/methylseq/public_BS/bwa-mem_markDuplicates/SRR5631375_1.sorted.markDups.bam\n",
      "taller/ra42hux/methylseq/public_BS/bwa-mem_markDuplicates/SRR5631376_1.sorted.markDups.bam\n",
      "taller/ra42hux/methylseq/public_BS/bwa-mem_markDuplicates/SRR5631378_1.sorted.markDups.bam\n",
      "taller/ra42hux/methylseq/public_BS/bwa-mem_markDuplicates/SRR5631379_1.sorted.markDups.bam\n",
      "taller/ra42hux/methylseq/public_BS/bwa-mem_markDuplicates/SRR5631380_1.sorted.markDups.bam\n",
      "taller/ra42hux/methylseq/public_BS/bwa-mem_markDuplicates/SRR5631381_1.sorted.markDups.bam\n",
      "taller/ra42hux/methylseq/public_BS/bwa-mem_markDuplicates/SRR5631382_1.sorted.markDups.bam\n",
      "taller/ra42hux/methylseq/public_BS/bwa-mem_markDuplicates/SRR5631383_1.sorted.markDups.bam\n",
      "taller/ra42hux/methylseq/public_BS/bwa-mem_markDuplicates/SRR5631385_1.sorted.markDups.bam\n",
      "taller/ra42hux/methylseq/public_BS/bwa-mem_markDuplicates/SRR5631386_1.sorted.markDups.bam\n",
      "taller/ra42hux/methylseq/public_BS/bwa-mem_markDuplicates/SRR5631389_1.sorted.markDups.bam\n",
      "taller/ra42hux/methylseq/public_BS/bwa-mem_markDuplicates/SRR5631390_1.sorted.markDups.bam\n",
      "taller/ra42hux/methylseq/public_BS/bwa-mem_markDuplicates/SRR5631391_1.sorted.markDups.bam\n",
      "taller/ra42hux/methylseq/public_BS/bwa-mem_markDuplicates/SRR5631392_1.sorted.markDups.bam\n"
     ]
    }
   ],
   "source": [
    "! ls taller/ra42hux/methylseq/public_BS/bwa-mem_markDuplicates/*sorted.markDups.bam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd583c1d-6d3b-489a-b593-ed687dee3f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eR92\tmethylseq/public_BS/bwa-mem_markDuplicates/SRR5631373_1.sorted.markDups.bam\n",
      "eR92\tmethylseq/public_BS/bwa-mem_markDuplicates/SRR5631374_1.sorted.markDups.bam\n",
      "eR92\tmethylseq/public_BS/bwa-mem_markDuplicates/SRR5631375_1.sorted.markDups.bam\n",
      "eR92\tmethylseq/public_BS/bwa-mem_markDuplicates/SRR5631376_1.sorted.markDups.bam\n",
      "eR150\tmethylseq/public_BS/bwa-mem_markDuplicates/SRR5631378_1.sorted.markDups.bam\n",
      "eR150\tmethylseq/public_BS/bwa-mem_markDuplicates/SRR5631379_1.sorted.markDups.bam\n",
      "eR150\tmethylseq/public_BS/bwa-mem_markDuplicates/SRR5631380_1.sorted.markDups.bam\n",
      "eR150\tmethylseq/public_BS/bwa-mem_markDuplicates/SRR5631381_1.sorted.markDups.bam\n",
      "eR193\tmethylseq/public_BS/bwa-mem_markDuplicates/SRR5631382_1.sorted.markDups.bam\n",
      "eR193\tmethylseq/public_BS/bwa-mem_markDuplicates/SRR5631383_1.sorted.markDups.bam\n",
      "eR193\tmethylseq/public_BS/bwa-mem_markDuplicates/SRR5631385_1.sorted.markDups.bam\n",
      "eR193\tmethylseq/public_BS/bwa-mem_markDuplicates/SRR5631386_1.sorted.markDups.bam\n",
      "Col0\tmethylseq/public_BS/bwa-mem_markDuplicates/SRR5631389_1.sorted.markDups.bam\n",
      "Col0\tmethylseq/public_BS/bwa-mem_markDuplicates/SRR5631390_1.sorted.markDups.bam\n",
      "Col0\tmethylseq/public_BS/bwa-mem_markDuplicates/SRR5631391_1.sorted.markDups.bam\n",
      "Col0\tmethylseq/public_BS/bwa-mem_markDuplicates/SRR5631392_1.sorted.markDups.bam\n"
     ]
    }
   ],
   "source": [
    "# create a tab-sparated table for MethylScore (column headers are not required), having ID and location\n",
    "# thinking of scratch as my working directory\n",
    "! tail -n +2 taller/ra42hux/bs/SraAccList.csv | sed -E 's/,/\\t/g' | awk '{print $2 \"\\t\" \"methylseq/public_BS/bwa-mem_markDuplicates/\" $1 \"_1.sorted.markDups.bam\"}'\n",
    "! tail -n +2 taller/ra42hux/bs/SraAccList.csv | sed -E 's/,/\\t/g' | awk '{print $2 \"\\t\" \"methylseq/public_BS/bwa-mem_markDuplicates/\" $1 \"_1.sorted.markDups.bam\"}' > taller/ra42hux/methylseq/public_BS/bwa-mem_markDuplicates/samples.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce13590e-53b6-4999-b413-bd16a8dc13c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MethylScore won't work if the reference is not the same, so I downloaded the genome from iGenomes\n",
    "wget https://s3.amazonaws.com/igenomes.illumina.com/Arabidopsis_thaliana/Ensembl/TAIR10/Arabidopsis_thaliana_Ensembl_TAIR10.tar.gz\n",
    "gunzip Arabidopsis_thaliana_Ensembl_TAIR10.tar.gz\n",
    "tar -xvf Arabidopsis_thaliana_Ensembl_TAIR10.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dbe5c4d-eb37-4afb-8205-cba9a1baf47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: MethylSeq already does the Deduplication part with Picard (before the methylation calls), so we DON'T HAVE to do it again\n",
    "# Otherwise MethylScore will crash somehow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e987c1-6e9c-4ea0-9cd3-c7b7799c1c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# then run methylscore\n",
    "tmux new -s ms_grp\n",
    "\n",
    "nextflow run \\\n",
    "\tComputomics/MethylScore \\\n",
    "\t--SAMPLE_SHEET=methylseq/public_BS/bwa-mem_markDuplicates/samples.tsv \\\n",
    "\t--GENOME=ref/Arabidopsis_thaliana/Ensembl/TAIR10/Sequence/WholeGenomeFasta/genome.fa \\\n",
    "    --DO_DEDUP false \\\n",
    "    --PROJECT_FOLDER methylscore \\\n",
    "\t-profile biohpc_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73068ef-9e63-4952-bdcc-1e834308a00a",
   "metadata": {},
   "source": [
    "It takes ~45 min per sample. Output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb728f7-3b81-490a-91c5-72c0b2cc1592",
   "metadata": {},
   "outputs": [],
   "source": [
    "[bd/f0ebc8] process > CONSENSUS:SORT_BAM (eR193)                                            [100%] 16 of 16 ✔\n",
    "[63/550674] process > CONSENSUS:MERGE_BAM (Col0:[SRR5631391_1.sorted.markDups.sorted.bam... [100%] 4 of 4 ✔\n",
    "[25/8129a4] process > CONSENSUS:READ_STATISTICS (Col0)                                      [100%] 4 of 4 ✔\n",
    "[4b/4235f2] process > CONSENSUS:SPLIT_BAM (Col0:4)                                          [100%] 28 of 28 ✔\n",
    "[79/5deb22] process > CONSENSUS:METHYLDACKEL (Col0:4)                                       [100%] 28 of 28 ✔\n",
    "[db/351ebf] process > CONSENSUS:MATRIX:BUILD (5)                                            [100%] 7 of 7 ✔\n",
    "[6e/84fb26] process > SAMPLESHEET:GENERATE (genome_matrix.tsv)                              [100%] 1 of 1 ✔\n",
    "[6d/d7ea0e] process > MRS:CALL_MRS (eR92:genome_matrix.tsv)                                 [100%] 4 of 4 ✔\n",
    "[cb/e76867] process > MRS:MR_STATISTICS (eR193)                                             [100%] 4 of 4 ✔\n",
    "[13/9ad783] process > MRS:SPLIT_MRS (all:batchsize:500)                                     [100%] 1 of 1 ✔\n",
    "[4d/b4305c] process > DMRS:INDEX (genome_matrix.tsv)                                        [100%] 1 of 1 ✔\n",
    "[3e/83e485] process > DMRS:CALL_DMRS (CHH:all.MRbatch.94)                                   [100%] 276 of 276 ✔\n",
    "[81/c50fc5] process > DMRS:MERGE_DMRS (CG:all)                                              [100%] 3 of 3 ✔\n",
    "WARN: Failed to render DAG file: /dss/lxclscratch/0B/ra42hux/methylscore/MethylScore_graph.png\n",
    "Completed at: 23-Nov-2023 14:07:07\n",
    "Duration    : 2h 51m 11s\n",
    "CPU hours   : 36.6\n",
    "Succeeded   : 377"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6603bd0c-52ae-47fa-81f0-9f1ebebf5228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we can try using Col0 as a reference\n",
    "tmux new -s ms_ref\n",
    "\n",
    "nextflow run \\\n",
    "\tComputomics/MethylScore \\\n",
    "\t--SAMPLE_SHEET=methylseq/public_BS/bwa-mem_markDuplicates/samples.tsv \\\n",
    "\t--GENOME=ref/Arabidopsis_thaliana/Ensembl/TAIR10/Sequence/WholeGenomeFasta/genome.fa \\\n",
    "    --DO_DEDUP false \\\n",
    "    --PAIRWISE Col0 \\\n",
    "    --PROJECT_FOLDER methylscore_ref \\\n",
    "\t-profile biohpc_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cf73be-58d8-40f5-9bcb-82603ab103f5",
   "metadata": {},
   "source": [
    "## 23/11/23"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073401b8-9ee4-4b14-9188-b16ebb747b59",
   "metadata": {},
   "source": [
    "#### After comparing both outputs, I decided it is better to use the default group algorithm instead of the reference-based pairwise mode. In the group mode, all DMRs are, in principle, homologous. In this way, we ca use the DMR bed file to intersect the \"genome_matrix.tsv\" file to get the mean methylated Cs per sample, per DMR!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e324be-c765-4a06-89cc-b69406e2fd9a",
   "metadata": {},
   "source": [
    "NOTE: The second value in the genome matrix [X/X/X/X] is the percentage of methylation.\n",
    "    \n",
    "Ex: 40/20.0/1/4 --> 20% in that position\n",
    "\n",
    "From MethylDackel:\n",
    "\n",
    "    2/ The methylation percentage rounded to an integer\n",
    "    3/ The number of alignments/pairs reporting methylated bases\n",
    "    4/ The number of alignments/pairs reporting unmethylated bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd874a3-46cd-4f0e-bca4-8094696afd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I created a new environment with essential software\n",
    "conda create -n env_g nano r-base bedtools iqtree samtools vcftools htslib bcftools biscuit plink\n",
    "# I also installed dplyr and data.table inside R\n",
    "# I tried to install Tidyverse but some dependencies did not worked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14c7a20-67f7-4e89-af11-5f626d51fdf9",
   "metadata": {},
   "source": [
    "## 24/11/23"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ede361-6a09-4b3f-9078-bd72249cbb95",
   "metadata": {},
   "source": [
    "# WGBS of 169 epiRILs [PRJNA719410](https://www.ncbi.nlm.nih.gov/bioproject/PRJNA719410)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78d3a0f0-88aa-4f92-b691-2863c55e8ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2247863 on cluster biohpc_gen\n"
     ]
    }
   ],
   "source": [
    "# To download in parallel\n",
    "! sbatch scripts/download_raw.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8631f415-69f1-4986-a7d0-9aa3a622349d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLUSTER: biohpc_gen\n",
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "2247863_[447-500%5 biohpc_ge down_epi  ra42hux PD       0:00      1 (Resources)\n",
      "       2247863_446 biohpc_ge down_epi  ra42hux  R       0:00      1 hlegr1409n02\n",
      "       2247863_445 biohpc_ge down_epi  ra42hux  R       0:01      1 hlegr1409n03\n",
      "       2247863_440 biohpc_ge down_epi  ra42hux  R       0:20      1 hlegr1409n04\n",
      "       2247863_438 biohpc_ge down_epi  ra42hux  R       0:23      1 hlegr1409n03\n",
      "       2247863_439 biohpc_ge down_epi  ra42hux  R       0:23      1 hlegr1409n09\n"
     ]
    }
   ],
   "source": [
    "! squeue -u ra42hux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc2f7f0-2c4d-4282-9e87-103d00018928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 415 out of 458 were properly downloaded \n",
    "# it is possible that the cluster rejected some of the jobs, which need to be done again\n",
    "# first I will try with the bam files that were provided by Johannes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95802db7-fd64-437c-9670-18b07268025c",
   "metadata": {},
   "source": [
    "## 27/11/23"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293935d3-b162-44de-9ef2-a071af4adf07",
   "metadata": {},
   "source": [
    "To get the mean mehtylation rate per DMR per context per sample (MethylRille script)\n",
    "\n",
    "WORKFLOW:\n",
    "-- Get methylation rate (mR) per site/sample and intersect to the DMR BEDs, do it for each context (Bash + Bedtools)\n",
    "sed -E 's/\\w+\\/(\\w+\\.\\w+)\\/\\w+\\/\\w+/\\1/g'\n",
    "\n",
    "ND=$(wc -l DMRs.CG.bed | tr ' ' '\\n' | head -1)\n",
    "paste <(cat DMRs.CG.bed | cut -f 1-3) <(awk -v ND=\"$ND\" 'BEGIN { for (i = 1; i <= ND; i++) printf \"dmr_%d_CG%s\", i, (i < ND ? \"\\n\" : \"\") }')\n",
    "cat DMRs.CG.bed | cut -f 1-3 | awk '{ printf $0 \"\\t\" \"dmr_%d_CG\\n\", NR }' \n",
    "\n",
    "bedtools intersect -a <(genome_matrix.bed | awk '$4 == \"CG\"') -b dmr.bed -wb \n",
    "\n",
    "-- Calculate mean mR per DMR and produce matrices (binary and non-binary; in R)\n",
    "\n",
    "R needs the following columns in a tsv file:\n",
    "  \n",
    "      chr\n",
    "      pos\n",
    "      pos_rep\n",
    "      context\n",
    "      sample_i\n",
    "    ...\n",
    "      sample_j\n",
    "      chr_dmr\n",
    "      start_dmr\n",
    "      end_dmr\n",
    "      id_dmr\n",
    "\n",
    "-- Create phylogenetic tree (IQTree)\n",
    "\n",
    "-- Merge files so we have input ready for GWAS (Bash)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba5129e-1aae-462f-a432-1c5eaa3f27a9",
   "metadata": {},
   "source": [
    "# Methylome analysis epiRILs\n",
    "\n",
    "Location of the data:\n",
    "\n",
    "/dss/dsslegfs01/pn73so/pn73so-dss-0000/becker_common/read_data/epiRILs/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457fd33a-2e56-4360-be3f-21f1b6be7d7a",
   "metadata": {},
   "source": [
    "## 22/01/24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0edef4fc-583d-4fc0-9852-966cbbbb8996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eR102\tpresent\t/dss/dsslegfs01/pn73so/pn73so-dss-0000/becker_common/read_data/epiRILs/102R_All.bam\n",
      "eR103\tpresent\t/dss/dsslegfs01/pn73so/pn73so-dss-0000/becker_common/read_data/epiRILs/103R_All.bam\n",
      "eR107\tpresent\t/dss/dsslegfs01/pn73so/pn73so-dss-0000/becker_common/read_data/epiRILs/107R_All.bam\n",
      "eR118\tpresent\t/dss/dsslegfs01/pn73so/pn73so-dss-0000/becker_common/read_data/epiRILs/118R_All.bam\n",
      "eR12\tpresent\t/dss/dsslegfs01/pn73so/pn73so-dss-0000/becker_common/read_data/epiRILs/12R_All.bam\n",
      "eR131\tpresent\t/dss/dsslegfs01/pn73so/pn73so-dss-0000/becker_common/read_data/epiRILs/131R_All.bam\n",
      "eR13\tpresent\t/dss/dsslegfs01/pn73so/pn73so-dss-0000/becker_common/read_data/epiRILs/13R_All.bam\n",
      "eR146\tpresent\t/dss/dsslegfs01/pn73so/pn73so-dss-0000/becker_common/read_data/epiRILs/146R_All.bam\n",
      "eR157\tpresent\t/dss/dsslegfs01/pn73so/pn73so-dss-0000/becker_common/read_data/epiRILs/157R_All.bam\n",
      "eR160\tpresent\t/dss/dsslegfs01/pn73so/pn73so-dss-0000/becker_common/read_data/epiRILs/160R_All.bam\n"
     ]
    }
   ],
   "source": [
    "# create a tab-sparated table for MethylScore (column headers are not required), having ID and location\n",
    "# replace the name and the location of the data\n",
    "! cat taller/ra42hux/lines_with_methylome_data.tsv | sed -E 's/^eR(\\w+)\\t(\\w+)/eR\\1\\t\\2\\t\\/dss\\/dsslegfs01\\/pn73so\\/pn73so-dss-0000\\/becker_common\\/read_data\\/epiRILs\\/\\1R_All.bam/g' > taller/ra42hux/methylome_metadata.tsv\n",
    "! head taller/ra42hux/methylome_metadata.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6aa654b4-11ee-416e-9c2b-0a120f5a6734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create one metadata sheet for all lines and one for the lines in my experiment\n",
    "! cut -f 1,3 taller/ra42hux/methylome_metadata.tsv > taller/ra42hux/er_data/all/all_metadata.tsv\n",
    "! grep \"present\" taller/ra42hux/methylome_metadata.tsv | cut -f 1,3 > taller/ra42hux/er_data/exp/exp_metadata.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997959ab-8ff5-49d3-8971-c32df1bbae54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run methylscore with all lines\n",
    "# the bam files were generated with Bismark and they don't contail PCR duplicates\n",
    "# I repeated it on 29/01/24 using the modified fasta reference to include the mitochondria and the chloroplast\n",
    "tmux new -s eR_all\n",
    "\n",
    "source activate env_nf\n",
    "\n",
    "nextflow run \\\n",
    "\tComputomics/MethylScore \\\n",
    "\t--SAMPLE_SHEET=er_data/all/all_metadata.tsv \\\n",
    "\t--GENOME=ref/Arabidopsis_thaliana/Ensembl/TAIR10/Sequence/WholeGenomeFasta/genome_CM.fa \\\n",
    "    --DO_DEDUP false \\\n",
    "    --MR_MIN_COV 5 \\\n",
    "    --PROJECT_FOLDER er_data/all \\\n",
    "\t-profile biohpc_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31138120-3dba-4bb1-a918-2eecf0840b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now just the lines I used in my experiment\n",
    "# I repeated it on 29/01/24 using the modified fasta reference to include the mitochondria and the chloroplast\n",
    "\n",
    "tmux new -s eR_exp\n",
    "\n",
    "source activate env_nf\n",
    "\n",
    "nextflow run \\\n",
    "\tComputomics/MethylScore \\\n",
    "\t--SAMPLE_SHEET=er_data/exp/exp_metadata.tsv \\\n",
    "\t--GENOME=ref/Arabidopsis_thaliana/Ensembl/TAIR10/Sequence/WholeGenomeFasta/genome_CM.fa \\\n",
    "    --DO_DEDUP false \\\n",
    "    --MR_MIN_COV 5 \\\n",
    "    --PROJECT_FOLDER er_data/exp \\\n",
    "\t-profile biohpc_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767cd98a-8f4d-445f-9455-0a29b0121b38",
   "metadata": {},
   "source": [
    "I used a minimum of 5 reads to support a methylation call\n",
    "\n",
    "Reference https://www.nature.com/articles/nmeth.3152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922cf279-383a-4465-a7e6-ce74e5f09798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to check or open tmux sessions\n",
    "tmux ls\n",
    "tmux attach -t eR_all\n",
    "tmux attach -t eR_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad06a304-b466-4f9e-99ee-469ba9356bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I also downloaded the VCF and mC calls from the 1001 genomes/epigenomes\n",
    "wget https://1001genomes.org/data/GMI-MPI/releases/v3.1/1001genomes_snp-short-indel_with_tair10_only_ACGTN.vcf.gz # SNPs\n",
    "wget https://ftp.ncbi.nlm.nih.gov/geo/series/GSE54nnn/GSE54292/suppl/GSE54292_RAW.tar # GMI methylomes\n",
    "wget https://ftp.ncbi.nlm.nih.gov/geo/series/GSE43nnn/GSE43857/suppl/GSE43857_RAW.tar # Salk Methylomes\n",
    "    \n",
    "# and the Optimized reference database of TEs from https://urgi.versailles.inra.fr/Data/Transposable-elements/Arabidopsis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7406160-bcdf-46a1-a606-529b8df4dadf",
   "metadata": {},
   "source": [
    "Everything worked well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5434c7c2-809f-4ac5-b45f-b45af24f0f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select some lines to plot frequencies, matrix from all lines\n",
    "shuf -n 10000 genome_matrix.tsv |  sed -E 's/\\w+\\/(\\w+\\.\\w+)\\/\\w+\\/\\w+/\\1/g' > random_sample.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4372aee9-7fef-4fad-94d1-1ff286ee254a",
   "metadata": {},
   "source": [
    "## 26/01/24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00dd32a-fba5-4127-8af3-1f5be6a6a307",
   "metadata": {},
   "source": [
    "#### Recombination calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498607b9-8d85-4de1-a2b7-5f6abe175d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up of the variants\n",
    "# >80 % of representation\n",
    "# biallelic SNPs only\n",
    "# High quality\n",
    "# from 10 to 50 of coverage\n",
    "vcftools --vcf 1001genomes_snp-short-indel_with_tair10_only_ACGTN.vcf --remove-indels --max-missing 0.8 --min-alleles 2 --max-alleles 2 --minQ 25 --min-meanDP 10 --max-meanDP 50 --minDP 10 --maxDP 50 --recode --out bi_snps\n",
    "\n",
    "After filtering, kept 218371 out of a possible 119146348 Sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b7fc1a-e9c5-4d3b-8d34-fed42a30298e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimation of recombination rates, population level\n",
    "mutation rate Arath: 5.9e−9 (10.1126/science.1180677)\n",
    "    \n",
    "# first I installed PyRho and SMC++\n",
    "conda create -n env_rho phython==3.8 # lower than 3.12\n",
    "conda install -c conda-forge msprime\n",
    "git clone https://github.com/popgenmethods/ldpop.git ldpop\n",
    "pip install ldpop/\n",
    "git clone https://github.com/popgenmethods/pyrho.git pyrho\n",
    "pip install pyrho/\n",
    "\n",
    "# test PyRho\n",
    "python -m pytest pyrho/tests/tests.py\n",
    "\n",
    "# it worked well\n",
    "# I removed the environment since I couldn't install SMC++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c2d734-b5cf-4fde-8534-aac01277f0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will calculate pairwise R for the SNPs in each DMR using plink\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0379292-6744-471c-8fc3-93335d30038a",
   "metadata": {},
   "source": [
    "## 29/01/24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78462b01-afa9-4342-a5ad-2ab7e35d5e1d",
   "metadata": {},
   "source": [
    "#### Methylation-aware SNP calling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36effdb-7c1e-42c5-ae27-fd54d3bb859c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# requires nextflow 20.07.1, so I created a new environment\n",
    "conda create -n env_snp nextflow=20.07.1 charliecloud=0.30\n",
    "\n",
    "# run in a Tmux background session\n",
    "tmux new -s eR_snp\n",
    "\n",
    "source activate env_snp\n",
    "\n",
    "nextflow run epidiverse/snp \\\n",
    "    --input /dss/dsslegfs01/pn73so/pn73so-dss-0000/becker_common/read_data/epiRILs/ \\\n",
    "    --reference ref/Arabidopsis_thaliana/Ensembl/TAIR10/Sequence/WholeGenomeFasta/genome.fa \\\n",
    "    --output er_data/snps \\\n",
    "    --variants \\\n",
    "    --coverage 4 \\\n",
    "    -config biohpc_gen.config\n",
    "\n",
    "# there are issues with SAMTOOLs so the pipeline won't work\n",
    "conda remove --name env_snp --all\n",
    "\n",
    "# I added biscuit to env_g\n",
    "conda install bioconda::biscuit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cd218a-20c0-4da0-b65e-ffe9b27bf165",
   "metadata": {},
   "source": [
    "In the alingments, the mitochondrial reads are mapped to \"M\" and the Chloroplastid ones to \"C\"\n",
    "Meanwhile, the genome fasta has \"Mt\" and \"Pt\" as their names, respectively\n",
    "So I created another fasta with the names that match the BAM files:\n",
    "   \n",
    "    ref/Arabidopsis_thaliana/Ensembl/TAIR10/Sequence/WholeGenomeFasta/genome_CM.f\n",
    "\n",
    "sed 's/>Pt/>C/g' ref/Arabidopsis_thaliana/Ensembl/TAIR10/Sequence/WholeGenomeFasta/genome.fa | sed 's/>Mt/>M/g' > ref/Arabidopsis_thaliana/Ensembl/TAIR10/Sequence/WholeGenomeFasta/genome_CM.fa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0f5ab77a-5ca5-405f-b7c2-31dee567e205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a file to parallel-run the pre-processing for BISCUIT (from taller)\n",
    "ls er_data/snps/bam/*All.bam | sed -E 's/.bam$//g' > er_data/snps/key.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea750f97-4edb-40dc-831a-2c9388d129b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2303957 on cluster biohpc_gen\n"
     ]
    }
   ],
   "source": [
    "# prepare data for BISCUIT\n",
    "# requirements: Sorted and Indexed bam files, Indexed reference\n",
    "! sbatch scripts/pre_biscuit.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "773eb7c4-5d44-40de-a20c-d91c3c3c3752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2304923 on cluster biohpc_gen\n"
     ]
    }
   ],
   "source": [
    "# now run biscuit\n",
    "! sbatch scripts/biscuit.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "445979d0-44cd-42a4-acc8-f19a32509878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2309689 on cluster biohpc_gen\n"
     ]
    }
   ],
   "source": [
    "# to extract the SNPs\n",
    "# I tried two ways:\n",
    "\n",
    "# the built-in version from BISCUIT\n",
    "# biscuit vcf2bed -t snp biscuit_all.vcf.gz > only_snps.bed\n",
    "\n",
    "# to analyize substituion rates\n",
    "# cat only_snps.bed | awk '{print $0 \"\\t\" $4 $5}' | cut -f 1,2,10 | awk '{print $1\"_\"$2 \"\\t\" $3}' > substitution.bed\n",
    "\n",
    "# and a custom script that removes variants with methylation information and ambigous calls\n",
    "! sbatch scripts/biscuit_extract_snps.sh\n",
    "\n",
    "# mine was way faster!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e29ba2-78dd-46d3-a4db-2d0cda0b4709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean SNPs\n",
    "vcftools --gzvcf biscuit_snps.vcf.gz --remove-indels --max-missing 0.8 --min-alleles 2 --max-alleles 2 --minQ 25 --min-meanDP 10 --max-meanDP 50 --minDP 10 --maxDP 50 --recode --out biallelic_snps\n",
    "\n",
    "After filtering, kept 733438 out of a possible 57915573 Sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4599e7c-3ac2-46e4-81e6-8fe5211ef283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make bed file of biallelic SNPS\n",
    "grep -v \"#\" biallelic_snps.recode.vcf | awk '{print $1 \"\\t\"  $2 \"\\t\" $2 }' > biallelic_snps.bed\n",
    "\n",
    "# Counts of SNPs per chr:\n",
    "     1      2      3      4      5      M \n",
    "182800 121096 146246 115813 166839    644 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa33f195-e63e-4cb7-92c0-0288a19a8a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean annotation file and extract upstream and downstream seqs\n",
    "# I had to remove non-UTF8 characters\n",
    "cat genes_CM.bed | iconv -f utf-8 -t utf-8 -c | sed -E 's/ID=(AT\\w+)\\;\\N.*$/\\1/g' > clean_genes_CM.bed\n",
    "\n",
    "bedtools flank -i clean_genes_CM.bed -g chr_sizes.txt -l 1000 -r 0 -s | sed 's/gene/upstream_region/g' > upstream.bed\n",
    "bedtools flank -i clean_genes_CM.bed -g chr_sizes.txt -l 0 -r 1000 -s | sed 's/gene/downstream_region/g' > downstream.bed\n",
    "cat annotation_CM.bed downstream.bed upstream.bed > extended_annotation.bed\n",
    "\n",
    "# get SNPs that fail into the different genome elements\n",
    "# I choose to use only TE, gene and flanking regions\n",
    "cat tes.bed clean_genes_CM.bed upstream.bed downstream.bed > elements.bed\n",
    "\n",
    "bedtools intersect -a ../er_data/snps/biallelic_snps.bed -b elements.bed -wb | awk '{print $1 \"_\" $2 \"\\t\" $11 \"\\t\" $13 }' > ../er_data/snps/snp_intersection_genome_elements.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8627d7d2-94ae-4bf7-91a7-042d2faa3879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "plink --vcf biallelic_snps.recode.vcf --allow-extra-chr --make-bed --out plink/raw\n",
    "\n",
    "# Extract linked SNPs\n",
    "\n",
    "plink --bfile plink/raw --allow-extra-chr --set-missing-var-ids @:# --indep-pairwise 5 10 0.33 --out plink/linked\n",
    "\n",
    "# Prune the original SNP dataset to leave non-linked SNPs\n",
    "\n",
    "plink --bfile plink/raw --allow-extra-chr --set-missing-var-ids @:# --extract plink/linked.prune.in --make-bed --out plink/pruned\n",
    "    \n",
    "# There's strong LD, when applying those filters only very few SNPs are kept (<100) Even after playing with the filters\n",
    "# Of course, the population is inbred!\n",
    "\n",
    "# So I did the PCA with all SNPs\n",
    "plink --bfile plink/raw --allow-extra-chr --pca --out plink/pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a43a74-394c-4fe1-a76f-e11e18cfe1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Population statistics\n",
    "\n",
    "#heterozygosity\n",
    "vcftools --vcf biallelic_snps.recode.vcf --het --out plink/individual\n",
    "\n",
    "# recombination\n",
    "plink --bfile plink/raw --r --out plink/correlation_snps\n",
    "\n",
    "# haplotype blocks\n",
    "plink --bfile plink/raw --blocks --out plink/haplotypes\n",
    "\n",
    "# MAF\n",
    "plink --bfile plink/raw --freq --out plink/maf_per_site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5e334c-7adc-449a-bcba-13b7f5fb69ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I realized that the substitions are very biased and those SNPs are actually monomorphic, as it was previously described in a paper\n",
    "# I applied a filter and still obsverved a bias\n",
    "vcftools --gzvcf biscuit_snps.vcf.gz --remove-indels --max-missing 0.8 --min-alleles 2 --max-alleles 2 --maf 0.1 --recode --out plink/test\n",
    "\n",
    "After filtering, kept 1667 out of a possible 57915573 Sites\n",
    "\n",
    "vcftools --vcf plink/test.recode.vcf --remove-indels --max-missing 0.8 --min-alleles 2 --max-alleles 2 --maf 0.1 --minDP 4 --recode --out plink/test_filtered\n",
    "\n",
    "1.4k SNPs\n",
    "\n",
    "A>C A>G A>T T>A T>C T>G \n",
    "117 859  73 105 193 116 \n",
    "\n",
    "# I'll go now with Revelio and Freebayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8df763-e93e-4e3e-8255-6b1a843176d0",
   "metadata": {},
   "source": [
    "#### TE polymorphisms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7113baac-bdb4-40e9-95b8-1e4c5dd5e30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# installation of McClintock\n",
    "# first I installed mamba in its own env\n",
    "# note, the mcclintock env is inside the mamba env\n",
    "https://github.com/bergmanlab/mcclintock.git\n",
    "cd mcclintock\n",
    "source activate mamba\n",
    "mamba env create -f install/envs/mcclintock.yml --name mcclintock\n",
    "source activate mmclintock\n",
    "python3 mcclintock.py --install\n",
    "\n",
    "# IMPORTANT!!!!\n",
    "# For some reason, inside the main mcclintock folder, there has to be an identical copy of it with the same name\n",
    "# so, I copied the whole folder to another one, moved into it and then rename it. Don't copy it directly or you'll make a loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94ad2f44-f995-4805-9a7d-3f0e59a3fefb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2329655 on cluster biohpc_gen\n"
     ]
    }
   ],
   "source": [
    "# spli the bam files into fastq1 and fastq2\n",
    "! sbatch scripts/re-raw.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a83edba-ad8d-4d89-9de7-572daae515ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I downloaded the Araport11 annotation from Tair\n",
    "# edit chr names\n",
    "#! sed -E 's/Chr(\\w+)/\\1/g' Araport11_GFF3_genes_transposons.current.gff > annotation_CM.gff\n",
    "\n",
    "# to select only TEs\n",
    "! awk '$3 ==  \"transposable_element\" ' taller/ra42hux/ref/annotation_CM.gff > taller/ra42hux/ref/tes.gff\n",
    "! awk '$3 ==  \"transposable_element_gene\" ' taller/ra42hux/ref/annotation_CM.gff >> taller/ra42hux/ref/tes.gff\n",
    "! awk '$3 ==  \"transposon_fragment\" ' taller/ra42hux/ref/annotation_CM.gff >> taller/ra42hux/ref/tes.gff\n",
    "\n",
    "# at the end I didn't use it because the consensus families were not linked to the Araport Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b3bf1635-c8d5-4f04-a651-49a4682b0f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a key for parallel jobs\n",
    "! ls taller/ra42hux/er_data/fastq/ | sed -E 's/\\_\\w.fastq.gz//g' | sort | uniq > taller/ra42hux/er_data/tes/key.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0048fbaa-c4f9-4bbb-b994-5e697cf57076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2310352 on cluster biohpc_gen\n"
     ]
    }
   ],
   "source": [
    "# run the pipeline\n",
    "! rm -r taller/ra42hux/er_data/tes/mcclintock/\n",
    "! mkdir taller/ra42hux/er_data/tes/mcclintock\n",
    "! sbatch scripts/mcclintock.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5ee629-2daf-447f-913a-e8d2a9c14498",
   "metadata": {},
   "source": [
    "It was running but not working either complaining, so I discarted the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3738f6-614d-42e0-86e6-178a6ffd7126",
   "metadata": {},
   "source": [
    "#### 1/02/24"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d3211a40-d9bd-4b40-b9c6-3318e94dae95",
   "metadata": {},
   "source": [
    "Now trying with SPLITREADER\n",
    "We only care about new TE insertions so it's fine\n",
    "\n",
    "I installed Bowtie2 and Picard in \"env_g\"\n",
    "The confirgurtion files look tricky so I also discarded it\n",
    "I tried TEMP2 and it works with my current environment without any issue, so I'll go with it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb71d381-95dc-46df-a8e3-fd8c0027e019",
   "metadata": {},
   "source": [
    "#### 02/02/24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5aa80b00-a09d-4bb6-b05f-eb17086d8525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\t11896\t11976\t.\t.\t+\tAraport11\ttransposable_element\t.\tATCOPIA24\n",
      "1\t16882\t17009\t.\t.\t-\tAraport11\ttransposable_element\t.\tATREP4\n",
      "1\t17023\t18924\t.\t.\t+\tAraport11\ttransposable_element\t.\tATREP3\n",
      "1\t18330\t18642\t.\t.\t-\tAraport11\ttransposable_element\t.\tATHATN7\n",
      "1\t55675\t56576\t.\t.\t+\tAraport11\ttransposable_element\t.\tSIMPLEHAT1\n",
      "1\t76843\t77500\t.\t.\t+\tAraport11\ttransposable_element\t.\tTA11\n",
      "1\t78287\t78785\t.\t.\t-\tAraport11\ttransposable_element\t.\tHELITRONY1D\n",
      "1\t154330\t154418\t.\t.\t-\tAraport11\ttransposable_element\t.\tATLINE1_3A\n",
      "1\t193673\t194263\t.\t.\t-\tAraport11\ttransposable_element\t.\tATREP5\n",
      "1\t194263\t194300\t.\t.\t-\tAraport11\ttransposable_element\t.\tATREP3\n",
      "How many families do we have?\n",
      "39080\n",
      "How many families are in the database?\n",
      "326\n"
     ]
    }
   ],
   "source": [
    "# Clean bead file of TEs\n",
    "# The database and the annotation should have the same families\n",
    "! cat taller/ra42hux/ref/tes.bed | sed -E 's/ID.+as\\=(\\w+)$/\\1/g' > taller/ra42hux/ref/clean_tes.bed\n",
    "! head taller/ra42hux/ref/clean_tes.bed\n",
    "\n",
    "! echo \"How many families do we have?\"\n",
    "! cat taller/ra42hux/ref/clean_tes.bed | cut -f 10| sort | uniq -c | wc -l\n",
    "\n",
    "! echo \"How many families are in the database?\"\n",
    "! grep \">\" taller/ra42hux/ref/athaTEref_Opt.lib | sed 's/>//g' | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "59d6ef66-5820-4a58-89ae-edf5c7290ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searched 326 FASTA records.\n",
      "Found 317 IDs out of 317 in the ID list.\n"
     ]
    }
   ],
   "source": [
    "# Select annotations for those TE families present in the database\n",
    "# The Colot's library has even less consensus families [only 271] https://github.com/baduelp/public/tree/master/SPLITREADER/thaliana\n",
    "# We get 31056 annotations (46%)\n",
    "! awk 'FNR==NR{a[$0];next}{if (($10 in a)){print}}' <(grep \">\" taller/ra42hux/ref/athaTEref_Opt.lib | sed 's/>//g') taller/ra42hux/ref/clean_tes.bed > taller/ra42hux/ref/known_tes.bed\n",
    "# 317 families are present (97%)\n",
    "\n",
    "# now select those FASTA sequences that are in the annotation, to have fully-matching databases\n",
    "\n",
    "! perl -e ' ($id,$fasta)=@ARGV; open(ID,$id); while (<ID>) { s/\\r?\\n//; /^>?(\\S+)/; $ids{$1}++; } $num_ids = keys %ids; open(F, $fasta); $s_read = $s_wrote = $print_it = 0; while (<F>) { if (/^>(\\S+)/) { $s_read++; if ($ids{$1}) { $s_wrote++; $print_it = 1; delete $ids{$1} } else { $print_it = 0 } }; if ($print_it) { print $_ } }; END { warn \"Searched $s_read FASTA records.\\nFound $s_wrote IDs out of $num_ids in the ID list.\\n\" } ' <(cut -f 10 taller/ra42hux/ref/known_tes.bed | sort | uniq ) taller/ra42hux/ref/athaTEref_Opt.lib > taller/ra42hux/ref/known_tes_consensus.fa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55203f1d-772b-49b0-98af-11782d78e34e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2330100 on cluster biohpc_gen\n"
     ]
    }
   ],
   "source": [
    "# I installed bwa in \"env_g\" to create the bwa indexes for TEMP2\n",
    "# then I indexed the genome_CM file\n",
    "\n",
    "# run the script\n",
    "! sbatch scripts/temp2.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "280c2095-e942-47a3-9c05-2907accff59f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2329753 on cluster biohpc_gen\n"
     ]
    }
   ],
   "source": [
    "# I noticed eR10 had insertions but somehow the pipeline doesn't work \n",
    "# So I tried just this sample to test\n",
    "! sbatch scripts/temp2_eR10.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca133106-9cdd-4279-8679-c9e82d4962bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PUTATIVE INSERTIONS\n",
    "! find taller/ra42hux/er_data/tes/results -type f -name \"*.insertion.raw.bed\" -exec wc -l {} + > taller/ra42hux/er_data/tes/raw_insertions.list\n",
    "! find taller/ra42hux/er_data/tes/results -type f -name \"*.insertion.raw.bed\" -exec awk 'BEGIN {FS=OFS=\"\\t\"} {print $0, FILENAME}' {} + > taller/ra42hux/er_data/tes/raw_insertions.tsv\n",
    "# results\n",
    "! find taller/ra42hux/er_data/tes/results -type f -name \"*.insertion.bed\" -exec wc -l {} + > taller/ra42hux/er_data/tes/insertions.list\n",
    "! find taller/ra42hux/er_data/tes/results -type f -name \"*.insertion.bed\" -exec awk 'BEGIN {FS=OFS=\"\\t\"} {print $0, FILENAME}' {} + > taller/ra42hux/er_data/tes/insertions.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68e19b4-1bd7-4bff-a03f-39e1c9aaa0e1",
   "metadata": {},
   "source": [
    "### Revelio + FreeBayes SNPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "52178b8e-ba90-4541-b2fc-7b6f55e6ec61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2328826 on cluster biohpc_gen\n"
     ]
    }
   ],
   "source": [
    "# I installed Freebayes and Pysam for Revelio, Pysam was installed with pip!\n",
    "# Paper Revelio: https://link.springer.com/article/10.1186/s12864-022-08691-6\n",
    "\n",
    "! sbatch scripts/revelio.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52645005-1b75-49dd-8bbf-19d7862ff6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2329693 on cluster biohpc_gen\n"
     ]
    }
   ],
   "source": [
    "# create bam list file\n",
    "# ls er_data/snps_rev_bay/masked/*.bam > er_data/snps_rev_bay/bam.list\n",
    "\n",
    "# Sort and index every BAM so it can match the genome coordinates for multithreading\n",
    "! sbatch scripts/pre_freebayes.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6def4195-df3a-4fad-8f60-432689abfd32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2330050 on cluster biohpc_gen\n"
     ]
    }
   ],
   "source": [
    "# now run FreeBayes\n",
    "! sbatch scripts/freebayes.sh\n",
    "\n",
    "# the compression and sorting was done with a for loop since it needs to be after the multithreading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa39cbcb-8eee-40b8-a565-c2af6db21f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename VCF since all FreeBayes output are \"unknown\"\n",
    "for file in vcf/*.gz;\n",
    "do\n",
    "name=$(echo ${file} | sed 's/vcf\\///g' | sed 's/.vcf.gz//g');\n",
    "picard RenameSampleInVcf \\\n",
    "      INPUT=${file} \\\n",
    "      OUTPUT=vcf/named_${name}.vcf \\\n",
    "      NEW_SAMPLE_NAME=${name} ;\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ff3ce9-602d-404d-8336-ba235d03bfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in vcf/named*.vcf; do echo \"$file\"; bgzip -f --threads 16 $file; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba42ea4-9d1d-4d4a-9ef0-9a96930b72a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in vcf/named*.gz; do echo $file; bcftools index --threads 16 $file; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7823cfef-49ee-468c-a3c0-d8caac155142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the merging chrashes when processing many indels\n",
    "# remove all indels\n",
    "for file in vcf/named*.gz;\n",
    "do\n",
    "name=$(echo ${file} | sed 's/vcf\\/named//g' | sed 's/.vcf.gz//g') ;\n",
    "echo ${name} ;\n",
    "vcftools --gzvcf $file --remove-indels --recode --out vcf/only_snps.${name}.vcf ;\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362d2f94-7128-498b-9c1e-5f8ae2ff9a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now compress and index again\n",
    "for file in vcf/only_snps*.vcf; do echo \"$file\"; bgzip -f --threads 16 $file; done\n",
    "for file in vcf/only_snps*.gz; do echo $file; bcftools index --threads 16 $file; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802ee272-57ac-4172-b8e8-88514f9ae416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge VCF\n",
    "bcftools merge --file-list only_snps_named_vcf.list -o raw_snps.vcf --threads 16\n",
    "# it worked!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc846c5-daae-468d-aeec-2edca2198310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter biallelic SNPs by quality, MAF and representation\n",
    "vcftools --vcf raw_snps.vcf --max-missing 0.8 --min-alleles 2 --max-alleles 2 --maf 0.1 --minDP 4 --recode --out filtered\n",
    "# After filtering, kept 624 out of a possible 145987 Sites\n",
    "\n",
    "# Without representative SNPS\n",
    "vcftools --vcf raw_snps.vcf --min-alleles 2 --max-alleles 2 --maf 0.1 --minDP 4 --recode --out biallelic\n",
    "# After filtering, kept 128095 out of a possible 145987 Sites\n",
    "\n",
    "# so most of them are missing a lot! (0.004% vs 87%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab794324-106c-4187-a7bf-4f8dbe06160a",
   "metadata": {},
   "source": [
    "Population genetics statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce8f27b-11d1-4b4f-aef8-a45c39838249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check Substitution rates for each set\n",
    "grep -v \"^#\" filtered.recode.vcf | cut -f 1-5 | awk '{print $1 \"\\t\" $2 \"\\t\" $2 \"\\t\" $4 \">\" $5 }' > filtered.bed\n",
    "grep -v \"^#\" biallelic.recode.vcf | cut -f 1-5 | awk '{print $1 \"\\t\" $2 \"\\t\" $2 \"\\t\" $4 \">\" $5 }' > biallelic.bed\n",
    "\n",
    "#heterozygosity\n",
    "vcftools --vcf filtered.recode.vcf --het --out plink/individual\n",
    "\n",
    "# Load file\n",
    "plink --vcf filtered.recode.vcf --allow-extra-chr --make-bed --out plink/raw\n",
    "\n",
    "# Extract linked SNPs\n",
    "\n",
    "plink --bfile plink/raw --allow-extra-chr --set-missing-var-ids @:# --indep-pairwise 50 10 0.33 --out plink/linked\n",
    "# 272 of 624 variants removed.\n",
    "\n",
    "# Prune the original SNP dataset to leave non-linked SNPs\n",
    "plink --bfile plink/raw --allow-extra-chr --set-missing-var-ids @:# --extract plink/linked.prune.in --make-bed --out plink/pruned\n",
    "#  352 variants remaining\n",
    "    \n",
    "# run pca all SNPs and no-LD SNPs\n",
    "plink --bfile plink/raw --allow-extra-chr --pca --out plink/pca_all\n",
    "plink --bfile plink/pruned --allow-extra-chr --pca --out plink/pca_no-ld\n",
    "\n",
    "# calculate frequency distribution of rare variants [0.01>MAF<0.2] using complete biallelic SNP dataset\n",
    "plink --vcf biallelic.recode.vcf --allow-extra-chr --make-bed --out plink/full\n",
    "plink --bfile plink/full --allow-extra-chr --geno 0.2 --maf 0.01 --max-maf 0.2  --make-bed --out plink/rare\n",
    "\n",
    "# 36 SNPs left!\n",
    "\n",
    "# calculate counts for the whole data set\n",
    "plink --bfile plink/full --allow-extra-chr --set-missing-var-ids @:# --freq counts --out plink/maf_per_site "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c76e06-0790-4f8c-a84b-0cdd001117a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a phylogenetic tree\n",
    "# Took it from here: https://github.com/edgardomortiz/vcf2phylip\n",
    "# For heterozygous SNPs: \"chooses a nucleotide from a heterozygous genotype at random to avoid IUPAC\"\n",
    "python vcf2phylip.py -i taller/ra42hux/er_data/snps_rev_bay/filtered.recode.vcf \\\n",
    "                     --output-folder taller/ra42hux/er_data/snps_rev_bay/ \\\n",
    "                     --output-prefix filtered --fasta -r\n",
    "\n",
    "# I also created another one with ambious heterozygous calls \n",
    "# From IQTREE: each represented character will have equal likelihood\n",
    "# Why? Because randomly choosing one allele may bias the tree\n",
    "python vcf2phylip.py -i taller/ra42hux/er_data/snps_rev_bay/filtered.recode.vcf \\\n",
    "                     --output-folder taller/ra42hux/er_data/snps_rev_bay/ \\\n",
    "                     --output-prefix ambigous --fasta -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26d3b94-1845-44bb-a9fc-24b2e6d44fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ML trees\n",
    "iqtree -nt 4 -s ../filtered.min4.fasta -B 1000\n",
    "iqtree -nt 4 -s ../ambigous.min4.fasta -B 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcfddac8-856a-4041-afbb-68f4e871400a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy files and compare trees\n",
    "! cp taller/ra42hux/er_data/snps_rev_bay/ambigous.min4.fasta.contree /dss/dsslegfs01/pn73so/pn73so-dss-0000/becker_common/eddy/epixbiome/data/genetic.tree\n",
    "! cp taller/ra42hux/er_data/all/rille/phylo.tsv.fa.contree /dss/dsslegfs01/pn73so/pn73so-dss-0000/becker_common/eddy/epixbiome/data/epi-genetic.tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086ce329-3af7-4a4c-9f77-e5df9d6403a8",
   "metadata": {},
   "source": [
    "## Col-0, root vs leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70324eb3-a3b2-409f-a41f-575cd2f0e2ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2 leaf samples\n",
    "# 3 root samples, each sequenced in two lanes\n",
    "# leaf samples have probably more coverage since the files are twice the size\n",
    "# I used Bismark since it was also used for the epiRILs\n",
    "# I trimmed 5bp at both ends as Isaac recommended\n",
    "\n",
    "tmux new -s wt\n",
    "source activate env_nf\n",
    "\n",
    "nextflow run \\\n",
    "\tnf-core/methylseq \\\n",
    "\t--input 'wt/raw/*{1,2}.fastq.gz' \\\n",
    "\t--genome TAIR10 \\\n",
    "\t--aligner bismark \\\n",
    "\t--comprehensive \\\n",
    "\t--clip_r1 5 \\\n",
    "\t--clip_r2 5 \\\n",
    "\t--three_prime_clip_r1 5 \\\n",
    "\t--three_prime_clip_r2 5 \\\n",
    "\t--min_depth 4 \\\n",
    "\t--outdir wt/methylseq/ \\\n",
    "\t-profile biohpc_gen \\\n",
    "\t-r 1.6.1 \n",
    "\n",
    "______________________________________________________\n",
    "Completed at: 05-Feb-2024 17:52:36\n",
    "Duration    : 1h 30m 50s\n",
    "CPU hours   : 65.4\n",
    "Succeeded   : 44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "29f5a009-30ca-4c4c-885d-8199bae19469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2333715 on cluster biohpc_gen\n"
     ]
    }
   ],
   "source": [
    "# SNP calling with the data\n",
    "! sbatch scripts/snps_wt.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d9aac0-955f-4fb1-babb-948703d96b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge anc clean SNPs\n",
    "bcftools merge --file-list file.list -o raw_snps.vcf --threads 16\n",
    "vcftools --vcf raw_snps.vcf --max-missing 0.8 --min-alleles 2 --max-alleles 2 --maf 0.1 --minDP 4 --recode --out wt_filtered\n",
    "# After filtering, kept 3698 out of a possible 90807 Sites\n",
    "# more SNPs than the epiRIL population!\n",
    "\n",
    "# check Substitution rates for each set\n",
    "grep -v \"^#\" vcf/wt_filtered.recode.vcf | cut -f 1-5 | awk '{print $1 \"\\t\" $2 \"\\t\" $2 \"\\t\" $4 \">\" $5 }' > wt_filtered.bed\n",
    "\n",
    "# calculate counts for the whole data set\n",
    "plink --vcf vcf/wt_filtered.recode.vcf --double-id --allow-extra-chr --make-bed --out plink/wt_raw\n",
    "plink --bfile plink/wt_raw --allow-extra-chr --set-missing-var-ids @:# --freq counts --out plink/wt_maf_per_site "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "898e16a7-b172-44dd-b6c3-5d321e6deb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check it in the R Studio Server\n",
    "! cp taller/ra42hux/wt/snps/wt_filtered.bed /dss/dsslegfs01/pn73so/pn73so-dss-0000/becker_common/eddy/epixbiome/data/wt_snps.bed\n",
    "! cp taller/ra42hux/ref/clean_genes_CM.bed /dss/dsslegfs01/pn73so/pn73so-dss-0000/becker_common/eddy/epixbiome/data/genes.bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3d927057-8b88-4dac-8ef9-0997b6cd1acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leaf-1\twt/methylseq/bismark_deduplicated/leaf-1_1_val_1_bismark_bt2_pe.deduplicated.bam\n",
      "leaf-2\twt/methylseq/bismark_deduplicated/leaf-2_1_val_1_bismark_bt2_pe.deduplicated.bam\n",
      "root-1\twt/methylseq/bismark_deduplicated/root-1_1_val_1_bismark_bt2_pe.deduplicated.bam\n",
      "root-2\twt/methylseq/bismark_deduplicated/root-2_1_val_1_bismark_bt2_pe.deduplicated.bam\n",
      "root-3\twt/methylseq/bismark_deduplicated/root-3_1_val_1_bismark_bt2_pe.deduplicated.bam\n"
     ]
    }
   ],
   "source": [
    "# create metadata for methylscore\n",
    "! paste <(ls taller/ra42hux/wt/methylseq/bismark_deduplicated/*.bam | sed 's/taller\\/ra42hux\\///g' | sed -E 's/.+ed\\/(\\w+\\-\\w)_.+/\\1/g') <(ls taller/ra42hux/wt/methylseq/bismark_deduplicated/*.bam | sed 's/taller\\/ra42hux\\///g' ) > taller/ra42hux/wt/metadata_for_methylscore.tsv \n",
    "! cat taller/ra42hux/wt/metadata_for_methylscore.tsv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe79c642-3c4f-4060-b8e9-d2beb671ceaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run methylscore to call methylation\n",
    "tmux new -s wt\n",
    "source activate env_nf\n",
    "\n",
    "nextflow run \\\n",
    "\tComputomics/MethylScore \\\n",
    "\t--SAMPLE_SHEET=wt/metadata_for_methylscore.tsv \\\n",
    "\t--GENOME=ref/genome_CM.fa \\\n",
    "    --DO_DEDUP false \\\n",
    "    --MR_MIN_COV 5 \\\n",
    "    --PROJECT_FOLDER wt/methylscore \\\n",
    "\t-profile biohpc_gen\n",
    "\n",
    "________________________________________-\n",
    "Completed at: 05-Feb-2024 20:21:00\n",
    "Duration    : 2h 4m 54s\n",
    "CPU hours   : 25.3\n",
    "Succeeded   : 334"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "602aeff7-d9ff-4864-8b58-4165c7d04d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rwx-----x 1 ra42hux pn73so 2.6K Feb  7 12:27 .conda/envs/env_g/bin/surco.R\n"
     ]
    }
   ],
   "source": [
    "# I made scripts to process the output of MethyRille {KingSize}\n",
    "# copy the R script to bin/ folder of the environment\n",
    "! cp surco.R .conda/envs/env_g/bin/surco.R\n",
    "! chmod 701 .conda/envs/env_g/bin/surco.R\n",
    "! ls -lh .conda/envs/env_g/bin/surco.R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e2b96bb-8cdb-4f33-974b-0ec001aadd39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rwx-----x 1 ra42hux pn73so 709 Feb  6 16:38 .conda/envs/env_g/bin/tab_to_phy.pl\n"
     ]
    }
   ],
   "source": [
    "# Also copy the file to create a fasta file\n",
    "! cp tab_to_phy.pl .conda/envs/env_g/bin/tab_to_phy.pl\n",
    "! chmod 701 .conda/envs/env_g/bin/tab_to_phy.pl\n",
    "! ls -lh .conda/envs/env_g/bin/tab_to_phy.pl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de1190e-4848-43b2-ad91-a17713206a3b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# MethylRille"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd6f91ea-a93c-4c1a-9b86-af58982e7fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2335452 on cluster biohpc_gen\n",
      "Submitted batch job 2335453 on cluster biohpc_gen\n",
      "Submitted batch job 2335454 on cluster biohpc_gen\n"
     ]
    }
   ],
   "source": [
    "# I have to edit each run manually\n",
    "! sbatch scripts/methyl-rille_wt.sh\n",
    "! sbatch scripts/methyl-rille_all.sh\n",
    "! sbatch scripts/methyl-rille_exp.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c72f27cf-5156-4788-8a5c-888e5d6022c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy files to make PCA in R\n",
    "! cp taller/ra42hux/er_data/all/rille/mean_matrix.tsv /dss/dsslegfs01/pn73so/pn73so-dss-0000/becker_common/eddy/epixbiome/data/all_matrix.tsv\n",
    "! cp taller/ra42hux/er_data/exp/rille/mean_matrix.tsv /dss/dsslegfs01/pn73so/pn73so-dss-0000/becker_common/eddy/epixbiome/data/exp_matrix.tsv\n",
    "! cp taller/ra42hux/er_data/all/rille/binary_matrix.tsv /dss/dsslegfs01/pn73so/pn73so-dss-0000/becker_common/eddy/epixbiome/data/all_bin.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b023ae5-0a67-4baa-8eb7-c6fb4204271a",
   "metadata": {},
   "source": [
    "#### Cleaning of the DMRs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4088f7-d79d-4f3b-868e-b09bf003abc8",
   "metadata": {},
   "source": [
    "Create list of \"unwanted DMRs\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "91d0da6d-eba4-4e7f-bc63-b914e4eff0de",
   "metadata": {},
   "source": [
    "My Rstudio Project is located here:\n",
    "\n",
    "/dss/dsslegfs01/pn73so/pn73so-dss-0000/becker_common/eddy/epixbiome/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320e8cfc-3b8a-4d13-809b-ad0641754917",
   "metadata": {},
   "source": [
    "##### 1.- Clean DMRs that change between roots and leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9869cddc-2710-47b1-8a2a-203ce4fd7217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do the differential methylation analysis between roots and leaves\n",
    "! cp taller/ra42hux/wt/rille/mean_matrix.tsv /dss/dsslegfs01/pn73so/pn73so-dss-0000/becker_common/eddy/epixbiome/data/root_leaf_matrix.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2fa346c-d100-43fb-a82f-0edcf45f84d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the list\n",
    "! cat /dss/dsslegfs01/pn73so/pn73so-dss-0000/becker_common/eddy/epixbiome/data/root_leaf_differential_mC.tsv | awk '$6 == \"dm\" ' | cut -f 1 > taller/ra42hux/er_data/root_vs_leaf.list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326b5928-8742-4b70-91a1-d53f744541dd",
   "metadata": {},
   "source": [
    "##### 2.- Clean CG DMRs that match with genes with at least 80% of the region"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc1b2bd-2c1c-44a0-a7be-b4c128779fd9",
   "metadata": {},
   "source": [
    "- From 27242 CG DMRs;\n",
    "\n",
    "- 14770, 15062 and 16395 are covered at the 100, 80 and 10%, respectively, by at least one full gene annotations (all that is transcribed)\n",
    "\n",
    "- 12570, 13773 and 19774 are covered at the 100, 80 and 10% by an exonic annotation, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fc8308-53c1-4b7a-a57c-239f984ac8bd",
   "metadata": {},
   "source": [
    "NOT DOING IT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a791d854-735b-43aa-9342-900e615fc5db",
   "metadata": {},
   "source": [
    "##### 3.- Clean DMRs that overlap with SNPs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb03e242-6acf-4567-b91b-f087b3837006",
   "metadata": {},
   "source": [
    "NOT DOING IT\n",
    "\n",
    "-Why? Considering the origin of the epiRIL population, most SNPs should be in  low frequencies and those that are not should then be from the parents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b37dc2a-3be3-485e-aa10-31a76672aeb9",
   "metadata": {},
   "source": [
    "##### 4.- Clean DMRs that never are unmethylated (<15% methylation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc2df14-6430-4eab-9c92-0b09d9f7a90a",
   "metadata": {},
   "source": [
    "ONLY FOR THE BINARY ANALYSIS"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d143613a-fa3f-4a75-959c-e123b1a30624",
   "metadata": {},
   "source": [
    "To delete folders fast:\n",
    "    \n",
    "rsync -a --delete trash/ path/\n",
    "    \n",
    "then use rm -R over the empty directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273a79f6-4682-4ff5-8a72-ce4b72ea2920",
   "metadata": {},
   "source": [
    "# Amplicon analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cc1f75-db1d-4ec5-8a9f-9cd2bdadb64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isntall BaseSpace from anaconda\n",
    "bs auth\n",
    "bs download project -i 409471065 -o amplicon/\n",
    "\n",
    "------- Test\n",
    "bwa mem -t 16 ../../ref/phix.fa ../Undetermined/Undetermined_S0_L001_R1_001.fastq ../Undetermined/Undetermined_S0_L001_R2_001.fastq | samtools view -@ 16 -b > test.bam\n",
    "8.7 % Maps to PhiX (~2M reads)\n",
    "\n",
    "32667186 + 0 in total (QC-passed reads + QC-failed reads)\n",
    "2869681 + 0 mapped (8.78% : N/A)\n",
    "32562914 + 0 paired in sequencing\n",
    "16281457 on each read\n",
    "\n",
    "-------- Now check overlaps with my indexes\n",
    "One read is enough since they all should be the same\n",
    "grep \"1:N:0\" Undetermined_S0_L001_R1_001.fastq | sed -E 's/.+1\\:N\\:0\\://g' | sort | uniq > indexes.list\n",
    "\n",
    "Only 98 combinations have either the i5 or the i7???\n",
    "\n",
    "The top 95 combinations (based on the number of reads) have from 300k to 60k reads! Then it jumps to 11k\n",
    "It makes sense in terms of samples\n",
    "\n",
    "--------------\n",
    "My Forward barcodes went to the reverse read (NNNNNNNN+HHHHHHHH)\n",
    "And the reverse barcodes in the \"reverse complement\" form in the forward read (HHHHHHHH+NNNNNNNN)\n",
    "\n",
    "      8 ACGCTACT\n",
    "      8 ACTACGAC\n",
    "      8 ACTCACTG\n",
    "      8 CGAGAGTT\n",
    "      9 CGAGCGAC\n",
    "      8 CTGCGTAG\n",
    "      8 GACATAGT\n",
    "      9 GTCTATGA\n",
    "      9 GTCTGCTA\n",
    "      8 TAGTCTCC\n",
    "      9 TATAGCGA\n",
    "      8 TGAGTACG\n",
    "        \n",
    "\n",
    "     12 ACTATCTG\n",
    "     12 ATCGTACG\n",
    "     12 CGTGAGTG\n",
    "     12 CTGCGTGT\n",
    "     12 GACACCGT\n",
    "     12 GGATATCT\n",
    "     12 TAGCGAGT\n",
    "     12 TCATCGAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7bdaa0-aa33-4693-9970-1b7165c4967e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Demultiplexing using STACKS and the corrected indexes\n",
    "# ITS\n",
    "awk '$5 == \"its\"' ../barcodes_full.tsv | awk '{print $11 \"\\t\" $12 \"\\t\" $8}' > undt_its/its.barcodes\n",
    "process_radtags -P -p undt_its/ -b undt_its/its.barcodes --index-index -r --disable-rad-check -o undt_its/demux/\n",
    "\n",
    "# delete empty files\n",
    "find ./ -size 0 -print -delete\n",
    "\n",
    "# The 96 lines that have more than 100k in sizes are the ones sequenced\n",
    "find . -type f -size +100k | wc -l\n",
    "\n",
    "# 16S pool 1\n",
    "awk '$5 == \"16s\"' ../barcodes_full.tsv | awk '$6 == \"P1\" '| awk '{print $11 \"\\t\" $12 \"\\t\" $8}' > 16s/pool_1.barcodes\n",
    "process_radtags -P -p pool_1_raw/ -b pool_1.barcodes --index-index -r --disable-rad-check -o demux_pool_1/\n",
    "\n",
    "# Pool 2\n",
    "# For the Run:\n",
    "awk '$5 == \"16s\"' ../barcodes_full.tsv | awk '$6 == \"P2\" '| awk '{print $8 \"\\t\" $11 \"\\t\" $12}' > 16s/pool_2_indexes.tsv\n",
    "grep \"BS\" 16s/pool_1.barcodes | awk '{print $3 \"\\t\" $1 \"\\t\" $2}' >> 16s/pool_2_indexes.tsv\n",
    "\n",
    "# for the demultiplex\n",
    "awk '$5 == \"16s\"' ../barcodes_full.tsv | awk '$6 == \"P2\" '| awk '{print $11 \"\\t\" $12 \"\\t\" $8}' > 16s/pool_2.barcodes\n",
    "grep \"BS\" 16s/pool_1.barcodes >> 16s/pool_2.barcodes\n",
    "\n",
    "# Demux\n",
    "process_radtags -P -p 16s/pool2_raw/ -b 16s/pool_2.barcodes --index-index -r --disable-rad-check --barcode-dist-2 0 -o 16s/pool2_raw/demux/\n",
    "\n",
    "# delete bad/empty files\n",
    "find 16s/pool2_raw/demux/ -type f -name \"*.gz\" -size -4000k -delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe607d53-5a2a-4234-9dd4-c48b18ba10ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy ITS reads to analyze on R\n",
    "# remove small files: find . -type f -name \"*.fq\" -size -100k -delete\n",
    "! cp taller/ra42hux/amplicon/its/demux/*.fq /dss/dsslegfs01/pn73so/pn73so-dss-0000/becker_common/eddy/epixbiome/raw/its/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e030bf60-0c4d-4506-b5c3-917a6f207c3d",
   "metadata": {},
   "source": [
    "### Rhizosphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a423cd37-4e7a-422c-aa35-a7bd65a6d895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy rhizosphere from pool1 \n",
    "\n",
    "#find . -type f -name \"*.fq\" -size -100k -delete\n",
    "#rm *rem*\n",
    "\n",
    "! cp taller/ra42hux/amplicon/16s/demux_pool_1/*.gz /dss/dsslegfs01/pn73so/pn73so-dss-0000/becker_common/eddy/epixbiome/raw/16s/pool1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fa177d0-944c-47d1-8929-2f6f69c7b640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy pool2 samples\n",
    "! cp taller/ra42hux/amplicon/16s/pool2_raw/demux/*.gz /dss/dsslegfs01/pn73so/pn73so-dss-0000/becker_common/eddy/epixbiome/raw/16s/pool2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3362998-ec98-4224-89c3-4e32da3f3242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make ML trees of the sequences\n",
    "# ! cp /dss/dsslegfs01/pn73so/pn73so-dss-0000/becker_common/eddy/epixbiome/raw/pool1.fa taller/ra42hux/amplicon/trees/pool1.fa\n",
    "\n",
    "! cp /dss/dsslegfs01/pn73so/pn73so-dss-0000/becker_common/eddy/epixbiome/raw/rhizo.fa taller/ra42hux/amplicon/trees/rhizo.fa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddead4e3-4a27-4808-98bb-8d88bb150345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# align and make trees using the model as in https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-016-0992-y\n",
    "mafft --auto pool1.fa > pool1.aln #FFT-NS-2 \n",
    "iqtree -nt 16 -s pool1.aln -m GTR+I+G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55f959fa-baaa-4084-8fb3-9c13063effed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2383474 on cluster biohpc_gen\n"
     ]
    }
   ],
   "source": [
    "# I made an script as it would take a time\n",
    "#mafft --auto rhizo.fa > rhizo.aln\n",
    "#iqtree -nt 16 -s rhizo.aln -m GTR+I+G -B 1000\n",
    "\n",
    "! sbatch scripts/tree_rhizo.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f7e948f-5439-4e70-8ff9-1506184b82fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2370002 on cluster biohpc_gen\n"
     ]
    }
   ],
   "source": [
    "! sbatch scripts/tree_pool1.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "526cefc0-3fa1-484d-a2af-b5514c8dd3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp taller/ra42hux/amplicon/trees/rhizo.aln.treefile /dss/dsslegfs01/pn73so/pn73so-dss-0000/becker_common/eddy/epixbiome/raw/rhizo_tree.nw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21fc177-4feb-410c-ad5b-5b99f09bbc68",
   "metadata": {},
   "source": [
    "#### Endosphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c96b5f5-70b9-4442-a6c4-2bd1fdabeaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy sequences to make a tree\n",
    "! cp /dss/dsslegfs01/pn73so/pn73so-dss-0000/becker_common/eddy/epixbiome/raw/endo.fa taller/ra42hux/amplicon/trees/endo.fa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdd2ec4-6a8a-4bb3-b075-f8153d3b541e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mafft --auto endo.fa > endo.aln\n",
    "iqtree -nt 16 -s endo.aln -m GTR+I+G -B 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "760c5a48-7943-4bd2-98f0-fd9fabc3bf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# move the tree to the RStudio server\n",
    "! cp taller/ra42hux/amplicon/trees/endo.aln.treefile /dss/dsslegfs01/pn73so/pn73so-dss-0000/becker_common/eddy/epixbiome/raw/endo_tree.nw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6dd7ba3-3531-4388-9d21-4e3769fd5151",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp taller/ra42hux/amplicon/trees/endo.aln.contree /dss/dsslegfs01/pn73so/pn73so-dss-0000/becker_common/eddy/epixbiome/raw/endo_contree.nw\n",
    "! cp taller/ra42hux/amplicon/trees/rhizo.aln.contree /dss/dsslegfs01/pn73so/pn73so-dss-0000/becker_common/eddy/epixbiome/raw/rhizo_contree.nw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4e580e-91d4-4a03-9a8c-ebe4ffa1373e",
   "metadata": {},
   "source": [
    "### Looking for the causal gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bd7edb-c7f9-47dc-ae14-f98b4244bfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download root data\n",
    "wget https://ftp.ncbi.nlm.nih.gov/geo/series/GSE79nnn/GSE79710/suppl/GSE79710_RAW.tar\n",
    "tar -xvf GSE79710_RAW.tar\n",
    "gunzip *.gz\n",
    "\n",
    "# I removed the controls and the lower columnella"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ceb9d87d-0e82-48c2-9a26-c37934783e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the bed file of the candidates\n",
    "! cp /dss/dsslegfs01/pn73so/pn73so-dss-0000/becker_common/eddy/epixbiome/raw/candidate_dmrs.bed taller/ra42hux/amplicon/candidate/candidate_dmrs.bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b13b3b-6a45-4489-8902-af0082395e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As I am mostly interested in genes, I will only look for DMRs that intersect with genes OR the downstream/upstream regions (+-1kb)\n",
    "bedtools slop -i ../../ref/clean_genes_CM.bed -g ./../ref/chr_sizes.txt -b 1000 > extended_genes.bed\n",
    "\n",
    "# use 100% of the DMR regions to find overlaps\n",
    "bedtools intersect -a extended_genes.bed -b candidate_dmrs.bed -F 1 -wb | cut -f 10,15 > intersects.list\n",
    "# 26 unique genes but 30 total intersections, only 23 DMRs\n",
    "\n",
    "# select genes from the data and merge them into a file\n",
    "# include ACTIN2\n",
    "rm candidates_fpkm.tsv\n",
    "\n",
    "for i in raw/*fpkm*\n",
    "do\n",
    "name=$(echo ${i} | sed -E 's/.+\\km_(\\w+)\\.tsv/\\1/g' )\n",
    "awk 'FNR==NR{a[$0];next}{if (($1 in a)){print}}' <(cat <(echo AT3G18780) <(cut -f 1 intersects.list)) ${i} | awk -v name=\"$name\" '{ printf $0 \"\\t\" name \"\\n\" }' >> candidates_fpkm.tsv\n",
    "done\n",
    "\n",
    "\n",
    "# get the methylated sites from all tissues and the 23 intersecting DMRs\n",
    "# more than 5 reads to process a site\n",
    "# add actin\n",
    "awk 'FNR==NR{a[$0];next}{if (($5 in a)){print}}'  <(cut -f 2 intersects.list | sort | uniq) candidate_dmrs.bed | cut -f 1-5 > intersecting_dmrs.bed\n",
    "grep \"AT3G18780\" extended_genes.bed  | cut -f 1-4,10 >> intersecting_dmrs.bed\n",
    "\n",
    "rm candidates_mC.tsv\n",
    "\n",
    "for i in raw/*mc*\n",
    "do\n",
    "name=$(echo ${i} | sed -E 's/.+\\ls_(\\w+)\\.tsv/\\1/g' )\n",
    "bedtools intersect -a intersecting_dmrs.bed -b <(awk '{print $1 \"\\t\" $2 \"\\t\" $2 \"\\t\" $3 \"\\t\" $4 \"\\t\" $5 \"\\t\" $6}' <(tail -n +2 $i | awk '$6 > 5')) -wb | cut -f 5-12 | awk -v name=\"$name\" '{ printf $0 \"\\t\" name \"\\n\" }' >> candidates_mC.tsv\n",
    "echo \"${name} done!\"\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4e8c120-0820-4b2a-8e5a-39e1e69fb667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the results to the Server\n",
    "! cp taller/ra42hux/amplicon/candidate/candidates_mC.tsv /dss/dsslegfs01/pn73so/pn73so-dss-0000/becker_common/eddy/epixbiome/data/candidates_mC.tsv\n",
    "! cp taller/ra42hux/amplicon/candidate/candidates_fpkm.tsv /dss/dsslegfs01/pn73so/pn73so-dss-0000/becker_common/eddy/epixbiome/data/candidates_fpkm.tsv\n",
    "! cp taller/ra42hux/amplicon/candidate/intersects.list /dss/dsslegfs01/pn73so/pn73so-dss-0000/becker_common/eddy/epixbiome/data/intersects.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc9cb97-6e84-47ff-9938-22a862323998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the annotations of the LRR and other elements\n",
    "grep \"dmr_604_CG\" intersecting_dmrs.bed > LRR_neighborhood.bed\n",
    "grep \"AT1G10850\" ../../ref/clean_genes_CM.bed | cut -f 1-4,10 >> LRR_neighborhood.bed\n",
    "# 3 SNPs\n",
    "bedtools intersect -a LRR_neighborhood.bed -b ../../er_data/snps_rev_bay/biallelic.bed -wb | cut -f 6-8 >> LRR_neighborhood.bed\n",
    "# no TIPs\n",
    "# no reference TEs\n",
    "bedtools intersect -a <(bedtools slop -i LRR_neighborhood.bed -g ../../ref/chr_sizes.txt -b 1000) -b ../../ref/clean_tes.bed -F 0.1 | cut -f 1-4,10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3f64331-b060-4d7c-981e-7f04e5e4a42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp taller/ra42hux/amplicon/candidate/LRR_neighborhood.bed /dss/dsslegfs01/pn73so/pn73so-dss-0000/becker_common/eddy/epixbiome/data/LRR_neighborhood.bed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
